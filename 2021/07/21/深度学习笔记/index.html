<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css" integrity="sha256-2H3fkXt6FEmrReK448mDVGKb3WW2ZZw35gI7vqHOE4Y=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"fkingfree.github.io","root":"/","images":"/images","scheme":"Gemini","version":"8.6.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>
<meta name="description" content="“保持热爱，继续努力。”">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习笔记">
<meta property="og:url" content="https://fkingfree.github.io/2021/07/21/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="“保持热爱，继续努力。”">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2021-07-21T15:23:06.000Z">
<meta property="article:modified_time" content="2021-08-09T15:34:52.095Z">
<meta property="article:author" content="kingFree">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://fkingfree.github.io/2021/07/21/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://fkingfree.github.io/2021/07/21/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","path":"2021/07/21/深度学习笔记/","title":"深度学习笔记"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>深度学习笔记 | Hexo</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Hexo</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

   
    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>
    
      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80"><span class="nav-number">1.</span> <span class="nav-text">神经网络数学基础</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%A0%E9%87%8F%E8%BF%90%E7%AE%97"><span class="nav-number">1.1.</span> <span class="nav-text">张量运算</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E6%A2%AF%E5%BA%A6%E7%9A%84%E4%BC%98%E5%8C%96"><span class="nav-number">1.2.</span> <span class="nav-text">基于梯度的优化</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%A5%E9%97%A8"><span class="nav-number">2.</span> <span class="nav-text">神经网络入门</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%89%96%E6%9E%90"><span class="nav-number">2.1.</span> <span class="nav-text">神经网络剖析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#keras%E7%AE%80%E4%BB%8B%E4%B8%8E%E5%BB%BA%E7%AB%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B7%A5%E4%BD%9C%E7%AB%99"><span class="nav-number">2.2.</span> <span class="nav-text">keras简介与建立深度学习工作站</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%94%B5%E5%BD%B1%E8%AF%84%E8%AE%BA%E5%88%86%E7%B1%BB"><span class="nav-number">2.3.</span> <span class="nav-text">电影评论分类</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%981"><span class="nav-number">2.3.1.</span> <span class="nav-text">二分类问题1</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%982"><span class="nav-number">2.3.2.</span> <span class="nav-text">二分类问题2</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%983"><span class="nav-number">2.3.3.</span> <span class="nav-text">二分类问题3</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%96%B0%E9%97%BB%E5%88%86%E7%B1%BB"><span class="nav-number">2.4.</span> <span class="nav-text">新闻分类</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E5%88%86%E7%B1%BB%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-number">2.4.1.</span> <span class="nav-text">多分类的问题</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%A2%84%E6%B5%8B%E6%88%BF%E4%BB%B7"><span class="nav-number">2.5.</span> <span class="nav-text">预测房价</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%981"><span class="nav-number">2.5.1.</span> <span class="nav-text">回归问题1</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%982"><span class="nav-number">2.5.2.</span> <span class="nav-text">回归问题2</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80"><span class="nav-number">3.</span> <span class="nav-text">第四章-机器学习基础</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%9B%9B%E4%B8%AA%E5%88%86%E6%94%AF%E8%AF%84%E4%BC%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.1.</span> <span class="nav-text">机器学习的四个分支评估机器学习模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E3%80%81%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E3%80%81%E8%BF%87%E6%8B%9F%E5%90%88%E6%AC%A0%E6%8B%9F%E5%90%88"><span class="nav-number">3.2.</span> <span class="nav-text">数据预处理、特征工程、过拟合欠拟合</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%80%9A%E7%94%A8%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="nav-number">3.3.</span> <span class="nav-text">机器学习的通用工作流程</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AC%AC%E4%BA%94%E7%AB%A0%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%94%A8%E4%BA%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89"><span class="nav-number">4.</span> <span class="nav-text">第五章：深度学习用于计算机视觉</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%80%E4%BB%8B1"><span class="nav-number">4.1.</span> <span class="nav-text">卷积神经网络简介1</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%80%E4%BB%8B2"><span class="nav-number">4.2.</span> <span class="nav-text">卷积神经网络简介2</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9C%A8%E5%B0%8F%E5%9E%8B%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E8%AE%AD%E7%BB%83%E5%8D%B7%E7%A7%AF1"><span class="nav-number">4.3.</span> <span class="nav-text">在小型数据集上从头开始训练卷积1</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9C%A8%E5%B0%8F%E5%9E%8B%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E8%AE%AD%E7%BB%83%E5%8D%B7%E7%A7%AF2"><span class="nav-number">4.4.</span> <span class="nav-text">在小型数据集上从头开始训练卷积2</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C1"><span class="nav-number">4.5.</span> <span class="nav-text">使用预训练的神经网络1</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2"><span class="nav-number">4.6.</span> <span class="nav-text">使用预训练的神经网络2</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%AF%E8%A7%86%E5%8C%961"><span class="nav-number">4.7.</span> <span class="nav-text">卷积神经网络可视化1</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->
    
        <div class="site-overview-wrap sidebar-panel">
          <div class="site-overview">
            <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="kingFree"
      src="/images/tx.png">
  <p class="site-author-name" itemprop="name">kingFree</p>
  <div class="site-description" itemprop="description">要一直努力变优秀</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">13</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>



    <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=29498914&auto=1&height=66"></iframe>
          </div>
        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://fkingfree.github.io/2021/07/21/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/tx.png">
      <meta itemprop="name" content="kingFree">
      <meta itemprop="description" content="要一直努力变优秀">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          深度学习笔记
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-21 23:23:06" itemprop="dateCreated datePublished" datetime="2021-07-21T23:23:06+08:00">2021-07-21</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2021-08-09 23:34:52" itemprop="dateModified" datetime="2021-08-09T23:34:52+08:00">2021-08-09</time>
      </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p><strong>“保持热爱，继续努力。”</strong></p>
<span id="more"></span>

<h1 id="神经网络数学基础"><a href="#神经网络数学基础" class="headerlink" title="神经网络数学基础"></a>神经网络数学基础</h1><h2 id="张量运算"><a href="#张量运算" class="headerlink" title="张量运算"></a>张量运算</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">x=np.random.random((<span class="number">4</span>,<span class="number">5</span>))*<span class="number">10</span></span><br><span class="line"><span class="comment">#均匀分配抽0-1构成的4*5数组，每个数字再乘以10</span></span><br><span class="line"></span><br><span class="line">y=np.random.random((<span class="number">5</span>))*<span class="number">10</span></span><br><span class="line"><span class="comment">#1*5的数组，默认一行</span></span><br><span class="line"></span><br><span class="line">y=np.maximun(x,y)</span><br><span class="line"><span class="comment">#取最大值</span></span><br><span class="line"></span><br><span class="line">x=np.random.randint(<span class="number">30</span>,size=(<span class="number">3</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>))</span><br><span class="line"><span class="comment">#三组 两个2*4的矩阵</span></span><br><span class="line"></span><br><span class="line">y=x.sunm(axis=<span class="number">0</span>)</span><br><span class="line"><span class="comment">#沿着D0轴做加总 </span></span><br><span class="line"></span><br><span class="line">z=np.dot(x,y)</span><br><span class="line"><span class="comment">#向量的点乘</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#(a,b,c,d).(d,)-&gt;(a,b,c)</span></span><br><span class="line"><span class="comment">#(a,b,c,d).(d,e)-&gt;(a,b,c,e)</span></span><br><span class="line"></span><br><span class="line">y=x.reshape(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"><span class="comment">#把x矩阵写成两个3*4的矩阵</span></span><br><span class="line"></span><br><span class="line">z=np.transpose(y)</span><br><span class="line"><span class="comment">#转置 (2,3,4)--&gt;(4,3,2)</span></span><br><span class="line"> </span><br><span class="line">z=np.transpose(y,(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>))</span><br><span class="line"><span class="comment">#编号2的轴和编号1的轴对调,0轴不变</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="基于梯度的优化"><a href="#基于梯度的优化" class="headerlink" title="基于梯度的优化"></a>基于梯度的优化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fn</span>(<span class="params">x</span>):</span></span><br><span class="line">    fn=x**<span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> fn</span><br><span class="line"><span class="comment">#x的平方</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">derivate</span>(<span class="params">x</span>):</span></span><br><span class="line">    h=<span class="number">0.001</span></span><br><span class="line">    derivate=(fn(x+h)-fn(x-h))/(<span class="number">2</span>*h)</span><br><span class="line">    <span class="keyword">return</span> derivate</span><br><span class="line"><span class="comment">#微分</span></span><br><span class="line"></span><br><span class="line">eta=<span class="number">0.001</span></span><br><span class="line">num_iterate=<span class="number">1000</span></span><br><span class="line"></span><br><span class="line">x=<span class="number">2</span></span><br><span class="line">x_value=[x]</span><br><span class="line">fn_value=[fn(x)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_iterate):</span><br><span class="line">    x-=eta*(derivate(x))</span><br><span class="line">    x_value.append(x)</span><br><span class="line">    fn_value.append(fn(x))</span><br><span class="line"><span class="comment">#做一千次循环，把新产生的值存到[x]、[fn(x)]中</span></span><br><span class="line"></span><br><span class="line">y=np.<span class="built_in">max</span>(np.<span class="built_in">abs</span>(x_value))</span><br><span class="line"><span class="comment">#横轴根据x的绝对值的最大值</span></span><br><span class="line">z=np.linspace(-y,y,num_iterate)</span><br><span class="line"><span class="comment">#等分成一千份</span></span><br><span class="line"></span><br><span class="line">plt.plot(x_value,fn_value,<span class="string">&quot;bo&quot;</span>)</span><br><span class="line"><span class="comment">#蓝色：不断更新的值</span></span><br><span class="line">plt.plot(z,fn(z),<span class="string">&quot;r&quot;</span>)</span><br><span class="line"><span class="comment">#红色：真实的y=x**2的图形</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.ylable(<span class="string">&#x27;Function Value&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment">#坐标写一写，画图</span></span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></table></figure>

<h1 id="神经网络入门"><a href="#神经网络入门" class="headerlink" title="神经网络入门"></a>神经网络入门</h1><h2 id="神经网络剖析"><a href="#神经网络剖析" class="headerlink" title="神经网络剖析"></a>神经网络剖析</h2><h2 id="keras简介与建立深度学习工作站"><a href="#keras简介与建立深度学习工作站" class="headerlink" title="keras简介与建立深度学习工作站"></a>keras简介与建立深度学习工作站</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># The Sequential class</span></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line">model=model.Sequential()</span><br><span class="line"><span class="comment">#一层一层去做 </span></span><br><span class="line">model.add(layers.Dense(<span class="number">32</span>,activation=<span class="string">&#x27;relu&#x27;</span>,input_shape=(<span class="number">784</span>,)))</span><br><span class="line"><span class="comment">#第一个隐藏层神经元 输入层</span></span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>,activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"><span class="comment">#只需要写这一层有多少神经元，不用写上一次有多少神经元过来 </span></span><br><span class="line"><span class="comment">#softmax:希望每个数字都是几率的形式 加总=1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The functional API:</span></span><br><span class="line"><span class="comment">#很像函数的概念，每一层都是下一层的输入 </span></span><br><span class="line"></span><br><span class="line">input_tensor =layers.Input(shape=(<span class="number">784</span>,))</span><br><span class="line"><span class="comment">#输入层 一维</span></span><br><span class="line">x=layers.Dense(<span class="number">32</span>,activation=<span class="string">&#x27;relu&#x27;</span>)(input_tensor)</span><br><span class="line">output_tensor = layeer.Dense(<span class="number">10</span>,activation=<span class="string">&#x27;softmax&#x27;</span>)(x)</span><br><span class="line"><span class="comment">#输出层</span></span><br><span class="line">model = models.Model(inputs=input_tensor,outputs=outputs_tensor)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimizers</span><br><span class="line"></span><br><span class="line">model.cmpile(optimizer=optimizers.RMSprop(lr=<span class="number">0.001</span>),loss=<span class="string">&#x27;mse&#x27;</span>,metrics=[<span class="string">&#x27;accyracy&#x27;</span>])</span><br><span class="line"><span class="comment">#选一个优化器 选一个loss 还要选一个不错的监控指标</span></span><br><span class="line">model.fit(input_tensor,target_tensor,batch_size=<span class="number">128</span>,epochs=<span class="number">10</span>)</span><br><span class="line"><span class="comment">#估计参数 每次丢128个进去  跑十次</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="电影评论分类"><a href="#电影评论分类" class="headerlink" title="电影评论分类"></a>电影评论分类</h2><h3 id="二分类问题1"><a href="#二分类问题1" class="headerlink" title="二分类问题1"></a>二分类问题1</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> keras</span><br><span class="line">keras.__version__</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> imdb</span><br><span class="line"></span><br><span class="line">(train_data,train_labels),(test_data,test_labels)=(imdb.load_data(num_words=<span class="number">10000</span>))</span><br><span class="line"><span class="comment">#把他的数据全部下载下来</span></span><br><span class="line"></span><br><span class="line">?imdb.load_data <span class="comment">#</span></span><br><span class="line"><span class="comment">#查看num_words选多少最常用的的字，skip跳过常用的字，maxlen文章的长度，start_char=1文章开始,oov_char=2超过设定的字就是2，从3开始</span></span><br><span class="line"></span><br><span class="line">train_data[<span class="number">0</span>]</span><br><span class="line"><span class="comment">#看看长什么样子，开始是1，超过一万字是2</span></span><br><span class="line">train_labels[<span class="number">0</span>]</span><br><span class="line"><span class="comment">#结果是1  1是给正评 2是给负评</span></span><br><span class="line">train_data<span class="comment">#</span></span><br><span class="line"><span class="comment">#  </span></span><br><span class="line"></span><br><span class="line">train_data.shape<span class="comment">#</span></span><br><span class="line"><span class="comment">#(25000,)</span></span><br><span class="line">train_labels<span class="comment">#</span></span><br><span class="line">train_labels.shape<span class="comment">#</span></span><br><span class="line"><span class="comment">#(25000,)</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">max</span>([<span class="built_in">max</span>(sequence) <span class="keyword">for</span> sequence <span class="keyword">in</span> train_data])</span><br><span class="line"><span class="comment">#9999 看一下最大整数，0-9999</span></span><br><span class="line"><span class="comment">#把每一篇文章的最大整数抓出来 再取最大值</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#你假如很好奇的话可以把数字恢复成文字</span></span><br><span class="line">word_index = imdb.get_word_index()</span><br><span class="line"><span class="comment">#用字典的形态表示出来</span></span><br><span class="line">reverse_word_index = <span class="built_in">dict</span>([(value,key) <span class="keyword">for</span> (key,value) <span class="keyword">in</span> word_index.items()])</span><br><span class="line"><span class="comment">#在新的的字典里面，把原来的value摆在前面，key摆在后面</span></span><br><span class="line">decoded_review = <span class="string">&#x27;&#x27;</span>.join([reverse_word_index.get(i - <span class="number">3</span>,<span class="string">&#x27;?&#x27;</span>) <span class="keyword">for</span> i <span class="keyword">in</span> train_data[<span class="number">0</span>]])</span><br><span class="line"><span class="comment">#编码的时候每个字都加上3了，选择把他还原减3 2恢复成？</span></span><br><span class="line"></span><br><span class="line">word_index <span class="comment">#</span></span><br><span class="line"><span class="comment">#果然是个字典，使用频率吧越高，排序越小</span></span><br><span class="line">word_index.items()<span class="comment">#</span></span><br><span class="line">word_index.keys()<span class="comment">#</span></span><br><span class="line">word_index.values()<span class="comment">#</span></span><br><span class="line"></span><br><span class="line">word_index.get(<span class="string">&#x27;this&#x27;</span>)<span class="comment">#</span></span><br><span class="line"><span class="comment">#查一下this在字典里面的编号</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">len</span>(word_index)<span class="comment">#</span></span><br><span class="line"><span class="comment">#字典里一共有多少字</span></span><br><span class="line"></span><br><span class="line">word_index[<span class="string">&#x27;this&#x27;</span>]<span class="comment">#</span></span><br><span class="line"></span><br><span class="line">reverse_word_index.get(<span class="number">1</span>)<span class="comment">#</span></span><br><span class="line"><span class="comment">#看看最长用的字，是the</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="二分类问题2"><a href="#二分类问题2" class="headerlink" title="二分类问题2"></a>二分类问题2</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#资料预处理</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vectorize_sequences</span>(<span class="params">sequences,dimension=<span class="number">10000</span></span>):</span></span><br><span class="line"><span class="comment">#定义函数，输入data，输出矩阵形式</span></span><br><span class="line">    results = np.zeros((<span class="built_in">len</span>(sequences),dimension))</span><br><span class="line">    <span class="keyword">for</span> i, sequence <span class="keyword">in</span> <span class="built_in">enumerate</span>(sequences):</span><br><span class="line">        results[i, sequence] = <span class="number">1.</span><span class="comment"># </span></span><br><span class="line">        <span class="comment">#把对应的有值的那一栏填1，填在矩阵里</span></span><br><span class="line">    <span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line">x_train = vectorize_sequences(train_data)</span><br><span class="line"><span class="comment">#把训练资料变成25000乘10000的矩阵</span></span><br><span class="line">x_test = vectorize_sequences(test_data)</span><br><span class="line"><span class="comment">#把测试资料变成25000乘10000的矩阵</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np<span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vectorize_sequences</span>(<span class="params">sequences,dimension=<span class="number">10000</span></span>):</span></span><br><span class="line"><span class="comment">#定义函数，输入data，输出矩阵形式</span></span><br><span class="line">    results = np.zeros((<span class="built_in">len</span>(sequences),dimension))</span><br><span class="line">    <span class="keyword">for</span> i, value <span class="keyword">in</span> <span class="built_in">enumerate</span>(sequences):</span><br><span class="line">        results[i, value] = <span class="number">1.</span><span class="comment">#</span></span><br><span class="line">        <span class="comment">#把对应的有值的那一栏填1，填在矩阵里</span></span><br><span class="line">        <span class="built_in">print</span>((i,value),value)</span><br><span class="line">        <span class="built_in">print</span>(results)</span><br><span class="line">        <span class="comment">#装完1把做完一个文本的结果矩阵输出</span></span><br><span class="line">          <span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line">x_train = vectorize_sequences(train_data[<span class="number">0</span>:<span class="number">3</span>])</span><br><span class="line"><span class="comment">#把训练资料变成25000乘10000的矩阵</span></span><br><span class="line"><span class="built_in">print</span>(x_train0)</span><br><span class="line"><span class="built_in">print</span>(x_train0.shape)</span><br><span class="line"><span class="comment">#(3,10000)</span></span><br><span class="line"></span><br><span class="line">x_train[<span class="number">0</span>]</span><br><span class="line">x_train[<span class="number">0</span>].shape<span class="comment">#</span></span><br><span class="line"><span class="comment">#(10000,) 一维张量里面有一万个分量</span></span><br><span class="line"></span><br><span class="line">x_train <span class="comment">#</span></span><br><span class="line">x_train.shape <span class="comment">#</span></span><br><span class="line"><span class="comment">#(25000,10000)</span></span><br><span class="line"></span><br><span class="line">y_train = np.asarray(train_labels).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">y_test = np.asarray(test_labels).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line"><span class="comment">#把数据类型从整数变成浮点32</span></span><br><span class="line"></span><br><span class="line">y_train<span class="comment">#</span></span><br><span class="line"></span><br><span class="line">y_train.shape</span><br><span class="line"><span class="comment">#(25000,)</span></span><br><span class="line"></span><br><span class="line">叠神经网络</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>,activation=<span class="string">&#x27;relu&#x27;</span>,input_shape=(<span class="number">10000</span>,)))</span><br><span class="line"><span class="comment">#第一层要把input的维度写进来</span></span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>,activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>,activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line"><span class="comment"># 10000 16 16 1</span></span><br><span class="line">model.summary()<span class="comment">#</span></span><br><span class="line"><span class="comment">#查看每个隐藏层要估计的参数</span></span><br><span class="line"><span class="comment">#第一个隐藏层要估计的参数（10000+1）*16</span></span><br><span class="line"><span class="comment">#第二个 （16+1）*16</span></span><br><span class="line"><span class="comment">#第三个 （16+1）*1</span></span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;rmsprop&#x27;</span>,</span><br><span class="line">             loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">             meetrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"><span class="comment">#选rmsporp优化器，考虑一介导函数的部分，平方之后做一个指数化平滑</span></span><br><span class="line"><span class="comment">#二元分类就用二元交叉熵</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimizers</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.RMSprop(lr=<span class="number">0.001</span>),</span><br><span class="line">             loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">             metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"><span class="comment">#优化器自己设定学习速率，不然就和上面一样 用预设的东西来</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> losses</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> metrics</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.RMSprop(lr=<span class="number">0.001</span>),</span><br><span class="line">             loss=losses.binary_crossentropy,</span><br><span class="line">             metrics=[metrics.binary_accuracy])</span><br><span class="line"><span class="comment">#优化器自己设定loss、meetrics</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="二分类问题3"><a href="#二分类问题3" class="headerlink" title="二分类问题3"></a>二分类问题3</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#测试资料里面不能包含训练资料，不然就被污染了</span></span><br><span class="line">x_val = x_train[:<span class="number">10000</span>]</span><br><span class="line">partial_x_train=x_train[<span class="number">10000</span>:]</span><br><span class="line"></span><br><span class="line">y_val = y_train[:<span class="number">10000</span>]</span><br><span class="line">partial_y_train = y_train[<span class="number">10000</span>:]</span><br><span class="line"><span class="comment">#前一万个作为要验证的数据，后一万五作为训练数据</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">history = model.fit(partial_x_train,</span><br><span class="line">                   partial_y_train,</span><br><span class="line">                   epochs=<span class="number">20</span>,</span><br><span class="line">                   batch_size=<span class="number">512</span>,</span><br><span class="line">                   validation_data=(x_val,y_val))</span><br><span class="line"><span class="comment">#记录估计过程</span></span><br><span class="line"></span><br><span class="line">history_dict = history.history</span><br><span class="line">history_dict.keys()</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment">#开始画图</span></span><br><span class="line">acc = history.history[<span class="string">&#x27;binary_accuracy&#x27;</span>]</span><br><span class="line"><span class="comment">#训练资料的正确性</span></span><br><span class="line">val_acc = history.history[<span class="string">&#x27;val_binary_accuracy&#x27;</span>]</span><br><span class="line"><span class="comment">#验证资料的正确性</span></span><br><span class="line">loss = hiatory.history[<span class="string">&#x27;loss&#x27;</span>]</span><br><span class="line"><span class="comment">#训练资料的loss</span></span><br><span class="line">val_loss = history.history[<span class="string">&#x27;val_loss&#x27;</span>]</span><br><span class="line"><span class="comment">#验证资料的loss</span></span><br><span class="line"></span><br><span class="line">epochs = <span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">len</span>(acc) + <span class="number">1</span>)</span><br><span class="line"><span class="comment">#强制从1开始，python从0开始，为了让横轴从1开始</span></span><br><span class="line"></span><br><span class="line">plt.plot(epochs, loss, <span class="string">&#x27;bo&#x27;</span>, label=<span class="string">&#x27;Training loss&#x27;</span>)</span><br><span class="line"><span class="comment">#b--blue、o--圆形，代表训练资料</span></span><br><span class="line">plt.plot(epochs,val_loss,<span class="string">&#x27;b&#x27;</span>,label=<span class="string">&#x27;Validation loss&#x27;</span>)</span><br><span class="line"><span class="comment">#测试资料 蓝线</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.clf()</span><br><span class="line"><span class="comment">#清除图像</span></span><br><span class="line">acc = history_dict[<span class="string">&#x27;binary_accuracy&#x27;</span>]</span><br><span class="line"><span class="comment">#训练资料的正确性</span></span><br><span class="line">val_acc = hsitory_dict[<span class="string">&#x27;val_binary_accuracy&#x27;</span>]</span><br><span class="line"><span class="comment">#测试资料的正确性</span></span><br><span class="line">plt.plot(epochs,acc,<span class="string">&#x27;bo&#x27;</span>,label=<span class="string">&#x27;Training acc&#x27;</span>)</span><br><span class="line">plt.plot(epochs,val_acc,<span class="string">&#x27;b&#x27;</span>,label=<span class="string">&#x27;Training acc&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and validation acceracy&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">acc<span class="comment">#</span></span><br><span class="line">a = np.mean(acc)</span><br><span class="line"><span class="comment">#看一下训练资料的正确性，再求一下平均值</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>,activation=<span class="string">&#x27;relu&#x27;</span>,input_shape=(<span class="number">10000</span>,)))</span><br><span class="line"><span class="comment">#第一层要把input的维度写进来</span></span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>,activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>,activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line"><span class="comment"># 10000 16 16 1</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;rmsprop&#x27;</span>,</span><br><span class="line">             loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">             meetrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"><span class="comment">#选rmsporp优化器，考虑一介导函数的部分，平方之后做一个指数化平滑</span></span><br><span class="line"><span class="comment">#二元分类就用二元交叉熵</span></span><br><span class="line">model.fit(x_train,y_train,epochs=<span class="number">3</span>,batch_size=<span class="number">512</span>)</span><br><span class="line">results = model.evaluate(x_test,y_test)</span><br><span class="line"><span class="comment">#把一堆电脑没看过的资料全部丢进去</span></span><br><span class="line">results</span><br><span class="line"><span class="comment">#loss、准确率</span></span><br><span class="line"></span><br><span class="line">model.predict(x_test)</span><br><span class="line"><span class="comment">#每个评价是正评的概率</span></span><br><span class="line"><span class="comment">#用mse整个目标函数很平坦训练困难 </span></span><br><span class="line"></span><br><span class="line"><span class="comment">#混肴矩阵</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="新闻分类"><a href="#新闻分类" class="headerlink" title="新闻分类"></a>新闻分类</h2><h3 id="多分类的问题"><a href="#多分类的问题" class="headerlink" title="多分类的问题"></a>多分类的问题</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> reuters</span><br><span class="line"></span><br><span class="line">(train_data,train_labels),(test_data,test_labels) = reuters.load_data(num_words=<span class="number">10000</span>)</span><br><span class="line"><span class="comment">#选一万个最常用的整数</span></span><br><span class="line">?reuters.load_data<span class="comment">#</span></span><br><span class="line"><span class="comment">#和imdb的编码很像</span></span><br><span class="line"><span class="built_in">len</span>(train_data)</span><br><span class="line"><span class="built_in">len</span>(test_data)</span><br><span class="line"></span><br><span class="line">train_data[<span class="number">0</span>]</span><br><span class="line"><span class="comment">#看看编号0的data长什么样子</span></span><br><span class="line"></span><br><span class="line">word_index = reuters.get_word_index()</span><br><span class="line">reverse_word_index = <span class="built_in">dict</span>([(value, key) <span class="keyword">for</span> (key, value) <span class="keyword">in</span> word_index.items()])</span><br><span class="line"></span><br><span class="line">decoded_newswire =<span class="string">&#x27;&#x27;</span>.join([reverse_word_index.get(i-<span class="number">3</span>,<span class="string">&#x27;?&#x27;</span>) <span class="keyword">for</span> i <span class="keyword">in</span> train_data[<span class="number">0</span>]])</span><br><span class="line"><span class="comment">#减3是因为编码</span></span><br><span class="line">decoded_newswire</span><br><span class="line"><span class="comment">#找不出来的字就？</span></span><br><span class="line">train_labels[<span class="number">0</span>]</span><br><span class="line"><span class="comment">#3</span></span><br><span class="line">train_labels<span class="comment">#</span></span><br><span class="line"><span class="built_in">len</span>(word_index)<span class="comment">#</span></span><br><span class="line"><span class="comment">#新闻总共有多少不同的字</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vectorize_sequences</span>(<span class="params">sequences,dimension=<span class="number">10000</span></span>):</span></span><br><span class="line">    results = np.zeros((<span class="built_in">len</span>(sequences),dimension))</span><br><span class="line">    <span class="keyword">for</span> i,sequence <span class="keyword">in</span> <span class="built_in">enumerate</span>(sequences):</span><br><span class="line">        results[i,sequence]=<span class="number">1.</span></span><br><span class="line">    <span class="keyword">return</span> results</span><br><span class="line"><span class="comment">#哪些字出现，对应位置写1</span></span><br><span class="line">x_train = vectorize_sequences(train_data)</span><br><span class="line">x_test = vectorize_sequence(test_data)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">to_one_hot</span>(<span class="params">labels,dimension=<span class="number">46</span></span>):</span></span><br><span class="line">    results = np.zeros((<span class="built_in">len</span>(labels),dimension))</span><br><span class="line">    <span class="keyword">for</span> i,labels <span class="keyword">in</span> <span class="built_in">enumerate</span>(labels):</span><br><span class="line">        results[i,labels]=<span class="number">1.</span></span><br><span class="line">    <span class="keyword">return</span> results</span><br><span class="line"><span class="comment">#哪些字出现，对应位置写1，变成1乘46的向量</span></span><br><span class="line">one_hot_train_labels = to_one_hot(train_labels)</span><br><span class="line">one_hot_test_labels = to_one_hot(test_labels)</span><br><span class="line"></span><br><span class="line"><span class="comment">#详细版</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">to_one_hot</span>(<span class="params">labels,dimension=<span class="number">46</span></span>):</span></span><br><span class="line">    results = np.zeros((<span class="built_in">len</span>(labels),dimension))</span><br><span class="line">    <span class="keyword">for</span> i,labels <span class="keyword">in</span> <span class="built_in">enumerate</span>(labels):</span><br><span class="line">        results[i,labels]=<span class="number">1.</span></span><br><span class="line">        <span class="built_in">print</span>((i,label))</span><br><span class="line">        <span class="built_in">print</span>(results)        </span><br><span class="line">    <span class="keyword">return</span> results</span><br><span class="line"><span class="comment">#哪些字出现，对应位置写1，变成1乘46的向量</span></span><br><span class="line">one_hot_train_labels = to_one_hot(train_labels[<span class="number">0</span>:<span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(one_hot_train_labels)</span><br><span class="line"><span class="built_in">print</span>(one_hot_train_labels.shape)<span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.utils.np_utils <span class="keyword">import</span> to_categorical</span><br><span class="line"></span><br><span class="line">one_hot_train_labels = to_categorical(train_labels)</span><br><span class="line">one_hot_test_labels = to_categorical(test_labels)</span><br><span class="line"></span><br><span class="line">one_hot_train_labels<span class="comment">#</span></span><br><span class="line">one_hot_train_labels.shape<span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>,activation=<span class="string">&#x27;relu&#x27;</span>,input_shape=(<span class="number">10000</span>,)))</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>,activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">46</span>,activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"><span class="comment">#softmax 太聪明的设计</span></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;RMSProp&#x27;</span>,</span><br><span class="line">             loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">             metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#切一部分验证资料</span></span><br><span class="line">x_val = x_train[:<span class="number">1000</span>]</span><br><span class="line">partial_x_train = x_train[<span class="number">1000</span>:]</span><br><span class="line"></span><br><span class="line">y_val = one_hot_train_labels[:<span class="number">1000</span>]</span><br><span class="line">partial_y_train = one_hot_train_labels[<span class="number">1000</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment">#跑一下</span></span><br><span class="line">history = model.fit(partial_x_train,</span><br><span class="line">                   partial_y_train,</span><br><span class="line">                   epochs=<span class="number">20</span>,</span><br><span class="line">                   batch_size=<span class="number">521</span>,</span><br><span class="line">                   validation_data=(x_val,y_val))</span><br><span class="line"></span><br><span class="line"><span class="comment">#画图</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment">#开始画图</span></span><br><span class="line">loss = history.history[<span class="string">&#x27;loss&#x27;</span>]</span><br><span class="line"><span class="comment">#训练资料的损失</span></span><br><span class="line">val_loss = history.history[<span class="string">&#x27;val_loss&#x27;</span>]</span><br><span class="line"><span class="comment">#验证资料的损失</span></span><br><span class="line">epochs = <span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">len</span>(loss) + <span class="number">1</span>)</span><br><span class="line"><span class="comment">#强制从1开始，python从0开始，为了让横轴从1开始</span></span><br><span class="line"></span><br><span class="line">plt.plot(epochs, loss, <span class="string">&#x27;bo&#x27;</span>, label=<span class="string">&#x27;Training loss&#x27;</span>)</span><br><span class="line"><span class="comment">#b--blue、o--圆形，代表训练资料</span></span><br><span class="line">plt.plot(epochs,val_loss,<span class="string">&#x27;b&#x27;</span>,label=<span class="string">&#x27;Validation loss&#x27;</span>)</span><br><span class="line"><span class="comment">#测试资料 蓝线</span></span><br><span class="line">plt.title(<span class="string">&#x27;Training and validation loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.clf()</span><br><span class="line"><span class="comment">#清除图像</span></span><br><span class="line">acc = history_dict[<span class="string">&#x27;binary_accuracy&#x27;</span>]</span><br><span class="line"><span class="comment">#训练资料的正确性</span></span><br><span class="line">val_acc = hsitory_dict[<span class="string">&#x27;val_binary_accuracy&#x27;</span>]</span><br><span class="line"><span class="comment">#测试资料的正确性</span></span><br><span class="line">plt.plot(epochs,acc,<span class="string">&#x27;bo&#x27;</span>,label=<span class="string">&#x27;Training acc&#x27;</span>)</span><br><span class="line">plt.plot(epochs,val_acc,<span class="string">&#x27;b&#x27;</span>,label=<span class="string">&#x27;Training acc&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and validation acceracy&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#根据图像10个epoch之后，loss不再下降，所以再跑一遍，只跑十个</span></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>,activation=<span class="string">&#x27;relu&#x27;</span>,input_shape=(<span class="number">10000</span>,)))</span><br><span class="line">mpdel.add(layers.Dense(<span class="number">64</span>,activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layer.Dense(<span class="number">46</span>,activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;RMSProp&#x27;</span>,</span><br><span class="line">             loss=<span class="string">&#x27;categoricial_crossentropy&#x27;</span>,</span><br><span class="line">             metrice=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(partial_x_train,</span><br><span class="line">          partial_y_train,</span><br><span class="line">          epochs=<span class="number">10</span>,</span><br><span class="line">          batch_size=<span class="number">521</span>,</span><br><span class="line">          validation_data=(x_val,y_val))</span><br><span class="line">results = model.evalute(x_test,one_hot_test_labels)</span><br><span class="line"></span><br><span class="line">results</span><br><span class="line"><span class="comment">#准确率达到了78%</span></span><br><span class="line"></span><br><span class="line">prediction=model.predict_classes(x_test)<span class="comment">#</span></span><br><span class="line">prediction<span class="comment">#</span></span><br><span class="line"><span class="comment">#两千多笔都预测一下</span></span><br><span class="line"></span><br><span class="line">test_labels</span><br><span class="line"><span class="comment">#测试资料标准答案</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">pd.crosstab(test_labels,prediction,</span><br><span class="line">           rownames=[<span class="string">&#x27;label&#x27;</span>],colnames=[<span class="string">&#x27;predict&#x27;</span>])<span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="built_in">print</span>(classification_report(test_labels,prediction))<span class="comment">#</span></span><br><span class="line"><span class="comment">#有些类别没有被预测正确，正确率77这样</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line">test_labels_copy = copy.copy(test_labels)</span><br><span class="line">np.random.shuffle(test_labels_copy)</span><br><span class="line">flost(np.<span class="built_in">sum</span>(np.array(test_labels) == np.array(test_labels_copy)))/<span class="built_in">len</span>(test_labels)</span><br><span class="line"><span class="comment">#随便乱猜的几率是多少，</span></span><br><span class="line"><span class="comment">#测试资料标准答案复制一份打散，然后和正确答案比对，看一下几率</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#预测某一笔资料在每个类别的几率各是多少,加总=1</span></span><br><span class="line">predictions = model.predict(x_test)</span><br><span class="line"></span><br><span class="line">predictions[<span class="number">0</span>].shape</span><br><span class="line"><span class="comment">#(46,)</span></span><br><span class="line"></span><br><span class="line">predictions[<span class="number">0</span>]<span class="comment">#</span></span><br><span class="line"></span><br><span class="line">np.<span class="built_in">sum</span>(predictions[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">np.argmax(predictions[<span class="number">0</span>])</span><br><span class="line"><span class="comment">#看一下哪个数字最大</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#loss fuction 的另外一种写法</span></span><br><span class="line">y_train = np.array(train_labels)</span><br><span class="line">y_test = np.array(test_labels)</span><br><span class="line"></span><br><span class="line">y_train<span class="comment">#</span></span><br><span class="line"><span class="comment">#y不一定要做 to_categorical</span></span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;rmsprop&#x27;</span>,loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>,metrics=[<span class="string">&#x27;acc&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#如果某一层神经元突然比较少，可能会造成信息的贫瘠，除非你有特殊的原因，想把高维资料中重要的因素提取出来</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="预测房价"><a href="#预测房价" class="headerlink" title="预测房价"></a>预测房价</h2><h3 id="回归问题1"><a href="#回归问题1" class="headerlink" title="回归问题1"></a>回归问题1</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> keras</span><br><span class="line">keras.__version__</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> boston_housing</span><br><span class="line"></span><br><span class="line">(train_data,train_targets),(test_targets) =boston_housing.load_data()</span><br><span class="line"><span class="comment">#资料已经帮你分好了，有训练资料和测试资料</span></span><br><span class="line"></span><br><span class="line">？boston_housing.load_data</span><br><span class="line"><span class="comment">#检索一下</span></span><br><span class="line"></span><br><span class="line">train_data.shape</span><br><span class="line">(<span class="number">404</span>,<span class="number">13</span>)</span><br><span class="line">test_data.shape</span><br><span class="line">(<span class="number">102</span>,<span class="number">13</span>)</span><br><span class="line">train_targets</span><br><span class="line"></span><br><span class="line">mean = train_data.mean(axis=<span class="number">0</span>)</span><br><span class="line">train_data -= mean</span><br><span class="line">std = train_data.std(axis=<span class="number">0</span>)</span><br><span class="line">train_data/=std</span><br><span class="line"></span><br><span class="line">test_data -= mean</span><br><span class="line">test_data /= std</span><br><span class="line"><span class="comment">#标准化过程 训练资料测试资料标准化用的是训练资料的mean和标准差</span></span><br><span class="line"><span class="comment">#为了让电脑不知道 测试资料的内容</span></span><br><span class="line">mean<span class="comment">#</span></span><br><span class="line">std<span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#建构神经网络</span></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_model</span>():</span></span><br><span class="line">    model = models.Sequerntial()</span><br><span class="line">    model.add(layers.Dense(<span class="number">64</span>,activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                          input_shape=(train_data.shape[<span class="number">1</span>],)))</span><br><span class="line">    model.add(layers.Dense(<span class="number">64</span>,activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(layers.Dense(<span class="number">1</span>))</span><br><span class="line">    model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;rmsprop&#x27;</span>,loss=<span class="string">&#x27;mse&#x27;</span>,metrics=[<span class="string">&#x27;mae&#x27;</span>])</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"><span class="comment">#神经网络开小一点 不然电脑背答案 新资料就测不好</span></span><br><span class="line"><span class="comment">#作者比较喜欢用rmsprop，只有考虑loss function的梯度，训练的时候会有动量</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#资料量比较少，k—fold validation</span></span><br><span class="line"><span class="comment">#分成五份 其中五分之一做验证，其他做训练，做五次 ，加起来平均</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">k=<span class="number">4</span></span><br><span class="line">num_val_samples = <span class="built_in">len</span>(train_data)//k</span><br><span class="line">num_epochs = <span class="number">100</span></span><br><span class="line">all_scores = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;processing fold #&#x27;</span>,i)</span><br><span class="line">    val_data = train_data[i * num_val_samples: (i + <span class="number">1</span>) * num_val_samples]</span><br><span class="line">    val_targets = train_targets[i * num_val_samples: (i + <span class="number">1</span>) * num_val_samples]</span><br><span class="line">    </span><br><span class="line">    partial_train_data = np.concatenate(</span><br><span class="line">         [train_data[:i * num_val_samples],</span><br><span class="line">         train_data[(i + <span class="number">1</span>) * num_val_samples:]],</span><br><span class="line">         axis=<span class="number">0</span>)</span><br><span class="line">    partial train targets = np.concatenate(</span><br><span class="line">         [train_data[:i * num_val_samples],</span><br><span class="line">         train_data[(i + <span class="number">1</span>) * num_val_samples:]],</span><br><span class="line">         axis=<span class="number">0</span>)</span><br><span class="line">    partial_train_targets = np.concatenate(</span><br><span class="line">         [train_targets[:i * num_val_samples],</span><br><span class="line">         train_targets[(i + <span class="number">1</span>) * num_val_samples:]],</span><br><span class="line">         axis=<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    model = build_model()</span><br><span class="line">    model.fit(partial_train_data, partial_train_targets,</span><br><span class="line">             epochs=num_epochs,batch_size=<span class="number">1</span>,verbose=<span class="number">2</span>)</span><br><span class="line">    val_mse, val_mae = model.evaluate(val_data,val_targets,verbose=<span class="number">2</span>)</span><br><span class="line">    all_scores.append(val_mae)</span><br><span class="line"> <span class="comment">#verbose=2 进度条画给你看</span></span><br><span class="line">    </span><br><span class="line">all_scores</span><br><span class="line">np.mean(all_scores) </span><br><span class="line"><span class="comment">#四个验证资料的绝对误差的均值的均值</span></span><br><span class="line"><span class="comment">#少了些什么 ，之前loss画图 看出再第几个epoch overfitting</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="回归问题2"><a href="#回归问题2" class="headerlink" title="回归问题2"></a>回归问题2</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#做实验，跑五百个epoch，跑四次</span></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"></span><br><span class="line">K.clear_session()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">num_epochs = <span class="number">500</span></span><br><span class="line">all_mae_histories = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;processing fold #&#x27;</span>,i)</span><br><span class="line">    val_data = train_data[i * num_val_samples: (i + <span class="number">1</span>) * num_val_samples]</span><br><span class="line">    val_targets = train_targets[i * num_val_samples: (i + <span class="number">1</span>) * num_val_samples]</span><br><span class="line">    </span><br><span class="line">    partial_train_data = np.concatenate(</span><br><span class="line">         [train_data[:i * num_val_samples],</span><br><span class="line">         train_data[(i + <span class="number">1</span>) * num_val_samples:]],</span><br><span class="line">         axis=<span class="number">0</span>)</span><br><span class="line">    partial train targets = np.concatenate(</span><br><span class="line">         [train_data[:i * num_val_samples],</span><br><span class="line">         train_data[(i + <span class="number">1</span>) * num_val_samples:]],</span><br><span class="line">         axis=<span class="number">0</span>)</span><br><span class="line">    partial_train_targets = np.concatenate(</span><br><span class="line">         [train_targets[:i * num_val_samples],</span><br><span class="line">         train_targets[(i + <span class="number">1</span>) * num_val_samples:]],</span><br><span class="line">         axis=<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    model = build_model()</span><br><span class="line">    history = model.fit(partial_train_data, partial_train_targets,</span><br><span class="line">             epochs=num_epochs,batch_size=<span class="number">1</span>,verbose=<span class="number">2</span>)</span><br><span class="line">    val_mse, val_mae = model.evaluate(val_data,val_targets,verbose=<span class="number">2</span>)</span><br><span class="line">    mae_history = history.history[<span class="string">&#x27;val_mean_absolute_error&#x27;</span>]</span><br><span class="line">    all_mae_histories.append(mae_history) </span><br><span class="line"> <span class="comment">#verbose=2 进度条画给你看</span></span><br><span class="line"></span><br><span class="line">average_mae_history =[</span><br><span class="line">    np.mean([x[i] <span class="keyword">for</span> x <span class="keyword">in</span> all_mae_histories]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs)</span><br><span class="line">]</span><br><span class="line">average_mae_history<span class="comment">#</span></span><br><span class="line"></span><br><span class="line">np.argmin(average_mae_history)<span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">len</span>(average_mae_history)</span><br><span class="line"><span class="comment">#500，因为做了500个epoch</span></span><br><span class="line"></span><br><span class="line">AA = [[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">5</span>],[<span class="number">7</span>,<span class="number">9</span>]]<span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">len</span>(AA)<span class="comment">#</span></span><br><span class="line"><span class="comment">#3</span></span><br><span class="line"> </span><br><span class="line">np.mean([x[<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> AA])<span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#画图</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">len</span>(averange_mae_history) + <span class="number">1</span>),average_mae_history)</span><br><span class="line"><span class="comment">#强制横轴从1开始 </span></span><br><span class="line">ply.xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Validation MAE&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#指数平滑 砍掉前面十个点 做一遍</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">smooth_curve</span>(<span class="params">points,factor=<span class="number">0.9</span></span>):</span></span><br><span class="line">    smoothed_points = []</span><br><span class="line">    <span class="keyword">for</span> point <span class="keyword">in</span> points:</span><br><span class="line">        <span class="keyword">if</span> smoothen_points:</span><br><span class="line">            previous = smoothed_points[-<span class="number">1</span>]</span><br><span class="line">            smoothed_points.append(previous * factor + point * (<span class="number">1</span> - factor))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            smoothed_points.append(point)</span><br><span class="line">    <span class="keyword">return</span> smoothed_points</span><br><span class="line"></span><br><span class="line">smooth_mae_history = smooth_curve(average_mae_history[<span class="number">10</span>:])</span><br><span class="line"></span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">len</span>(smooth_mae_history) + <span class="number">1</span>),smooth_mae_history)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Validation MAE&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="built_in">len</span>(smooth_mae_history)<span class="comment">#</span></span><br><span class="line"><span class="comment">#490</span></span><br><span class="line">np.argmin(smooth_mae_history)<span class="comment">#</span></span><br><span class="line"><span class="comment">#34</span></span><br><span class="line"><span class="comment">#跑44个epoch就可以了</span></span><br><span class="line">model = build_model()</span><br><span class="line">model.fit(train_data,train_targets,</span><br><span class="line">         epoch=<span class="number">44</span>,batch_size=<span class="number">16</span>,verbose=<span class="number">0</span>)</span><br><span class="line">test_mse_score,test_mae_score = model.evaluate(test_data,test_targets)</span><br><span class="line"><span class="comment">#拿电脑从来没看过的资料去做</span></span><br><span class="line">test_mae_score</span><br><span class="line"></span><br><span class="line"><span class="comment">#小结：数据很少的话 用 K-fold 最好不要用很大的神经网络</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="第四章-机器学习基础"><a href="#第四章-机器学习基础" class="headerlink" title="第四章-机器学习基础"></a>第四章-机器学习基础</h1><h2 id="机器学习的四个分支评估机器学习模型"><a href="#机器学习的四个分支评估机器学习模型" class="headerlink" title="机器学习的四个分支评估机器学习模型"></a>机器学习的四个分支评估机器学习模型</h2><h2 id="数据预处理、特征工程、过拟合欠拟合"><a href="#数据预处理、特征工程、过拟合欠拟合" class="headerlink" title="数据预处理、特征工程、过拟合欠拟合"></a>数据预处理、特征工程、过拟合欠拟合</h2><p>神经网络不能太多也不能太小</p>
<p>太大没有一般化的能力</p>
<p>太小loss降得很慢 、over fitting的程度比较晚 </p>
<p>Dropout：每一层的output随机抽掉某个比例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#想在神经网络做这个事情,在每一层之后加这一行代码，丢掉百分之50</span></span><br><span class="line">model.add(layers.Dropout(<span class="number">0.5</span>))</span><br></pre></td></tr></table></figure>

<p><strong>结论</strong></p>
<p>对抗out fitting有这四种方法</p>
<p>1.让训练资料的数目更多</p>
<p>2.神经网络不要开的太大</p>
<p>3.在参数估计上做一下权重的正则化（不希望参数估计出来的值太大）</p>
<p>4.加入dropout（神经网络独有的绝招）</p>
<h2 id="机器学习的通用工作流程"><a href="#机器学习的通用工作流程" class="headerlink" title="机器学习的通用工作流程"></a>机器学习的通用工作流程</h2><p>想要解决什么问题？首先要有数据</p>
<p>分析你面对的是什么问题？是二元分类、多元分类、回归（y一个值）还是向量回归（y多个值，形成一个向量）、多类别单标签的分类问题，或者说是个非监督学习 clustering（距离分群），generation（深层模型教电脑去画一幅画写一首诗）</p>
<p>资料不平衡： precision 、recall </p>
<h1 id="第五章：深度学习用于计算机视觉"><a href="#第五章：深度学习用于计算机视觉" class="headerlink" title="第五章：深度学习用于计算机视觉"></a>第五章：深度学习用于计算机视觉</h1><h2 id="卷积神经网络简介1"><a href="#卷积神经网络简介1" class="headerlink" title="卷积神经网络简介1"></a>卷积神经网络简介1</h2><p>（如何利用深度学习教电脑去认识一些图片）</p>
<p>1.把要跑的层次上传到云端硬碟</p>
<p>2.右键开启工具colaboratory</p>
<p>3.代码执行程序、更改程序运行时类型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#把keras引进来</span></span><br><span class="line"><span class="comment">#hattps://keras.io/</span></span><br><span class="line">!pip install -q keras</span><br><span class="line"><span class="keyword">import</span> keras </span><br><span class="line"></span><br><span class="line"><span class="comment">#tensoflow with GPU  Colab  </span></span><br><span class="line"><span class="keyword">import</span> tensoflow <span class="keyword">as</span> tf</span><br><span class="line">device_name = tf.test.gpu_device_name()</span><br><span class="line"><span class="keyword">if</span> device_name != <span class="string">&#x27;/device:GPU:0&#x27;</span>:</span><br><span class="line">    <span class="keyword">raise</span> SystemError(<span class="string">&#x27;GPU device npt found&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Found GPU at: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(device_name))</span><br><span class="line"><span class="comment">#看到 Found GPU at :/device:GPU:0 说明你真的连上GPU了</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#卷积神经网络</span></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"></span><br><span class="line"><span class="comment">#用3乘3的小滤镜去学特征然后一直一格一格平移，每个区域都照一下</span></span><br><span class="line"><span class="comment">#每个格子都是0-255表示颜色深浅，最后会压缩在0-1</span></span><br><span class="line"><span class="comment">#28*28 共同享用同一组参数 只剩下26*26</span></span><br><span class="line">model = models.Sequnential()</span><br><span class="line">model.add(layers.(<span class="number">32</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">&#x27;relu&#x27;</span>,input_shape=(<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)))</span><br><span class="line"><span class="comment">#加入激活函数relu 非线性转换 得到要的层次</span></span><br><span class="line"><span class="comment">#keras规定要写(28,28,1) 卷积神经网络要写1 </span></span><br><span class="line"><span class="comment">#padding:same 这样先变成30*30 再变成28*28</span></span><br><span class="line"><span class="comment">#第一次做完得到 26*26 有32层</span></span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"><span class="comment">#MaxPooling2D 记录真正的精髓</span></span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>))          </span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">&#x27;relu&#x27;</span>)))</span><br><span class="line"><span class="comment">#小特征和小特征合成大特征</span></span><br><span class="line"><span class="comment">#第一个卷积层参数    （9*1+1）*32       (26,26,32)</span></span><br><span class="line"><span class="comment"># 第二个卷积层估计参数（9*32+1）*64     (13,13,32) 取一半</span></span><br><span class="line"><span class="comment">#第三               (9*64+1)*64     (11,11,64) 一半（5,5,64）    </span></span><br><span class="line"><span class="comment"># (3,3,64) 重要的特征都抓出来了 不是全域 是区域的相关性</span></span><br><span class="line"></span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line"><span class="comment">#摊平</span></span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>,activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>,activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"><span class="comment">#估计参数 （576+1）*64</span></span><br><span class="line">model.summary()</span><br><span class="line">  </span><br><span class="line"><span class="comment">#资料预处理</span></span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> to_categorical</span><br><span class="line"></span><br><span class="line">(train_images,train_labels),(test_images,teat_labels) = mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment">#变成四维张量</span></span><br><span class="line">train_images = train_images.reshape((<span class="number">60000</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)) </span><br><span class="line">train_images = train_images.astype(<span class="string">&#x27;float32&#x27;</span>)/<span class="number">255</span></span><br><span class="line"></span><br><span class="line">test_images = train_images.reshape((<span class="number">10000</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)) </span><br><span class="line">test_images = train_images.astype(<span class="string">&#x27;float32&#x27;</span>)/<span class="number">255</span></span><br><span class="line"></span><br><span class="line">train_labels = to_categorical(train_labels)</span><br><span class="line">test_labels = to_categorical(test_labels)</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;rmsprop&#x27;</span>,</span><br><span class="line">             loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">             metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(train_images,train_labels,epochs=<span class="number">5</span>,batch_size=<span class="number">64</span>)</span><br><span class="line">test_acc</span><br></pre></td></tr></table></figure>

<h2 id="卷积神经网络简介2"><a href="#卷积神经网络简介2" class="headerlink" title="卷积神经网络简介2"></a>卷积神经网络简介2</h2><p>1、平移不变性</p>
<p>2、空间层次结构</p>
<p>3、厚度取决于滤镜的数量</p>
<p>4、滤镜一般选择3乘3、大的5乘5</p>
<p>5、大小可以会改变，因为边界效应（可以先扩大原始图片 填0 ）</p>
<p>6、stride一般是1 ，6乘6移一格变成4乘4，移两格变成2乘2</p>
<p>7、max polling 用2乘2 每次移动2格，挑四个数字中最大的</p>
<p>8、没有max polling，图片缩小，没有所谓的层次学习的概念，三次卷积基本就等于一开始就用7乘7的滤镜</p>
<p>9、max polling 图片大小可以急剧下降。通常效果比较好</p>
<h2 id="在小型数据集上从头开始训练卷积1"><a href="#在小型数据集上从头开始训练卷积1" class="headerlink" title="在小型数据集上从头开始训练卷积1"></a>在小型数据集上从头开始训练卷积1</h2><p>1、不要让电脑两次看到两张一模一样的图片</p>
<p>2、 很多模型都可以利用，是深度学习的很大优势</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&#123;&#125; &#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="string">&quot;hello&quot;</span>,<span class="string">&quot;world&quot;</span>)<span class="comment">#</span></span><br><span class="line"><span class="comment">#&#x27;hello world&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;total training cat images:&#x27;</span>,<span class="built_in">len</span>(os.listdir(train_cats_dir)))</span><br><span class="line"><span class="comment">#total training cat images: 1000</span></span><br></pre></td></tr></table></figure>

<h2 id="在小型数据集上从头开始训练卷积2"><a href="#在小型数据集上从头开始训练卷积2" class="headerlink" title="在小型数据集上从头开始训练卷积2"></a>在小型数据集上从头开始训练卷积2</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#资料准备完毕，开始建构CNN的model</span></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"></span><br><span class="line"><span class="comment">#再次强调，想要学好一个模型，你得知道一共估计了多少个参数</span></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                       input_shape=(<span class="number">150</span>,<span class="number">150</span>,<span class="number">3</span>)))</span><br><span class="line"><span class="comment">#参数估计：（9乘3+1）乘32 、做完size：(148,148,32)</span></span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"><span class="comment">#                           size：(74,74,32)</span></span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"><span class="comment">#参数估计：（9乘32+1）乘64 、做完size：(72,72,64)</span></span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"><span class="comment">#                           size：(36,36,64)</span></span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"><span class="comment">#参数估计：（9乘64+1）乘128 、做完size：(34,34,128)</span></span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"><span class="comment">#                           size：(17,17,128)</span></span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"><span class="comment">#参数估计：（9乘128+1）乘128 、做完size：(15,15,128)</span></span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"><span class="comment">#                           size：(7,7,128)</span></span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line"><span class="comment">#摊平                        size：6272</span></span><br><span class="line">model.add(layers.Dense(<span class="number">512</span>,activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>,activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#写compile</span></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimizers</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">            optimizer=optimizers.RMSprop(1r=<span class="number">1e-4</span>),</span><br><span class="line">            metrics=[<span class="string">&#x27;acc&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#如何把图片变成数字，</span></span><br><span class="line"><span class="comment">#读取图片、解码变成数字（浮点张量），0-255压缩在0-1</span></span><br><span class="line"></span><br><span class="line">model.save(<span class="string">&#x27;cats_and_dogssmall_1.h5&#x27;</span>)</span><br><span class="line"><span class="comment">#以后可以把调出来继续训练 或者调出来预测</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#画图</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment">#战胜voer fitting 用 data augmentation</span></span><br><span class="line"><span class="comment">#旋转，宽度平移，上下平移，拉斜一点，变大变小，水平翻转</span></span><br><span class="line">datagen = ImageDataGenerator(</span><br><span class="line">      rotation_range=<span class="number">40</span>,</span><br><span class="line">      widtg_shift_range=<span class="number">0.2</span>,</span><br><span class="line">      hight_shift_range=<span class="number">0.2</span>,</span><br><span class="line">      shear_range=<span class="number">0.2</span>,</span><br><span class="line">      zoom_range=<span class="number">0.2</span>,</span><br><span class="line">      horizontal_flip=true,</span><br><span class="line">      fill_mode=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line"><span class="comment">#用临近的像素填补，新增的或不见的格子</span></span><br></pre></td></tr></table></figure>

<h2 id="使用预训练的神经网络1"><a href="#使用预训练的神经网络1" class="headerlink" title="使用预训练的神经网络1"></a>使用预训练的神经网络1</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#学会使用人家已经训练好的神经网络</span></span><br><span class="line"><span class="comment"># pre-trainde convnet</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.applications <span class="keyword">import</span> VGG16</span><br><span class="line"></span><br><span class="line">conv_base = VGG16(weight=<span class="string">&#x27;imagenet&#x27;</span>,</span><br><span class="line">                 include_top=<span class="literal">False</span>,</span><br><span class="line">                 input_shape=(<span class="number">150</span>,<span class="number">150</span>,<span class="number">3</span>))</span><br><span class="line"><span class="comment">#True的话 inout_shape就不能指定 就会有138357544个参数</span></span><br><span class="line"></span><br><span class="line">conv_base.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment">#看一下模型的图形  要安装graphviz模块（要设定环境变数）</span></span><br><span class="line"><span class="keyword">import</span> keras.utils <span class="keyword">import</span> plot_model</span><br><span class="line">plot_model(conv_base,show_shape=<span class="literal">True</span>,to_file=<span class="string">&#x27;VGG16.png&#x27;</span>)</span><br><span class="line"><span class="comment">#希望他变成一张图片VGG16.png</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> TPython.dislpay <span class="keyword">import</span> Image</span><br><span class="line">Image(filename=<span class="string">&#x27;VGG16.png&#x27;</span>)<span class="comment">#</span></span><br><span class="line"><span class="comment">#下一步导入猫和狗 预测一下</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="使用预训练的神经网络2"><a href="#使用预训练的神经网络2" class="headerlink" title="使用预训练的神经网络2"></a>使用预训练的神经网络2</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#原始模型 </span></span><br><span class="line">conv_basetop = VGG16(weight=<span class="string">&#x27;imagenet&#x27;</span>,</span><br><span class="line">                 include_top=<span class="literal">True</span>)<span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras.preprosessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"></span><br><span class="line">base_dir=<span class="string">&quot;Dpwnload\cats_and_dogs_small &quot;</span></span><br><span class="line"></span><br><span class="line">train-<span class="built_in">dir</span> = 0s.path.join(base_dir,<span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">validation_dir = os.path.join(base_dir,<span class="string">&#x27;validation&#x27;</span>)</span><br><span class="line">test_dir = os.path.join(base_dir,<span class="string">&#x27;test&#x27;</span>)</span><br><span class="line">datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line"><span class="comment">#压缩到0-1</span></span><br><span class="line">batch_size = <span class="number">20</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义特诊提前函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_features</span>(<span class="params">directory,sample_count</span>):</span></span><br><span class="line">    features = np.zeros(shape=(sample_count,<span class="number">4</span>,<span class="number">4</span>,<span class="number">512</span>))</span><br><span class="line">    <span class="comment">#开一个4维的0矩阵，</span></span><br><span class="line">    labels =np.zeros(shape=(sample_count))</span><br><span class="line">    <span class="comment">#标准答案不是0就是1，开1维的张量</span></span><br><span class="line">    generator = datagen.flow_from_directory(</span><br><span class="line">        directory,</span><br><span class="line">        target_size(<span class="number">150</span>,<span class="number">150</span>),</span><br><span class="line">        batch_size=batch_size,</span><br><span class="line">        class_mode=<span class="string">&#x27;bindary&#x27;</span>)</span><br><span class="line">    <span class="comment">#只要两类 bindary</span></span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> inputs_batch,labels_batch <span class="keyword">in</span> gengerator:</span><br><span class="line">        features_batch = conv_base.predict(inputs_batch)</span><br><span class="line">        feature[i * batch_size: (i+<span class="number">1</span>) * batch_size] = feature_batch</span><br><span class="line">        labels[i * batch_size: (i+<span class="number">1</span>) * batch_size] = labels_batch</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> i*batch_size &gt;=sample_count:</span><br><span class="line">            berak</span><br><span class="line">    <span class="keyword">return</span> features,labels</span><br><span class="line"></span><br><span class="line">train_features,train_labels = extract_feature(train_dir,<span class="number">2000</span>)</span><br><span class="line">validation_features,validation_labels = extract_feature(validation_dir,<span class="number">1000</span>)</span><br><span class="line">test_features,test_labels = extract_feature(test_dir,<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line">train_features = np.reshape(train_features,(<span class="number">2000</span>,<span class="number">4</span> *<span class="number">4</span>*<span class="number">512</span>))</span><br><span class="line">validation_features = np.reshape(validation_features,(<span class="number">1000</span>,<span class="number">4</span> *<span class="number">4</span>*<span class="number">512</span>))</span><br><span class="line">test_features = np.reshape(test_features,(<span class="number">1000</span>,<span class="number">4</span> *<span class="number">4</span>*<span class="number">512</span>))</span><br><span class="line">        </span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimizer</span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">256</span>,activation=<span class="string">&#x27;relu&#x27;</span>,input_dim=<span class="number">4</span>*<span class="number">4</span>*<span class="number">512</span>))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>,activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.RMSprop(1r=<span class="number">2e-5</span>),</span><br><span class="line">             loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">             metrics=[<span class="string">&#x27;acc&#x27;</span>])</span><br><span class="line"></span><br><span class="line">history = model.fit(train_features,train_labels,</span><br><span class="line">                   epoch=<span class="number">30</span>,batch_size=<span class="number">20</span>,</span><br><span class="line">                   validation_data=(validation_features,validatuion_labels))</span><br><span class="line"></span><br><span class="line"><span class="comment">#画图</span></span><br><span class="line"><span class="comment">#第一个方式：把自己的图片巩固人家所训练的模型，得到一些特征的提取，再接一个小小的神经网络</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#第二个方式 </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line">model = model.Sequential()</span><br><span class="line">model.add(conv_base)</span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dense(<span class="number">256</span>,activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>,activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.summary() </span><br><span class="line"></span><br><span class="line"><span class="comment">#冻结人家设置好的东西不要动它</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="卷积神经网络可视化1"><a href="#卷积神经网络可视化1" class="headerlink" title="卷积神经网络可视化1"></a>卷积神经网络可视化1</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#有人说深度学习是黑盒子 不知道规则</span></span><br><span class="line"><span class="comment">#卷积神经网络可以视觉化</span></span><br><span class="line"><span class="comment">#看一下卷积神经网络的中间输出到底是怎么一回事</span></span><br><span class="line"><span class="comment">#视觉化神经网络的过滤器 找一个输入最容易激活神经网络中的某个过滤器</span></span><br><span class="line"><span class="comment">#视觉化类激活的热力图 电脑看到了哪些东西会觉得这张图片是非洲象</span></span><br><span class="line"><span class="comment">#丢一只猫进去 路径自己设一下</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#把图片变成数字</span></span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#变成150*150的</span></span><br><span class="line">img = image.load_img(img_path,target_size=(<span class="number">150</span>,<span class="number">150</span>))</span><br><span class="line"><span class="comment">#把图片变成数字 三维 </span></span><br><span class="line">img_tensor = image.img_to_array(img)</span><br><span class="line"><span class="comment">#图片必须是四维丢进CNN 加一个0轴  </span></span><br><span class="line">img_tenspr = np.expand_dims(img_tensor,axis=<span class="number">0</span>)</span><br><span class="line">img_tensor /=<span class="number">225.</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(img_tensor.shape)</span><br><span class="line"><span class="comment">#(1,150,150,3)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment">#把数字以图片的方式显现出来</span></span><br><span class="line">plt.imshow(img_tensor[<span class="number">0</span>])</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#一个输入多个输出 多个输入多个输出models.Model()</span></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"></span><br><span class="line">layer_outputs = [layer.output <span class="keyword">for</span> layer <span class="keyword">in</span> model.layer[:<span class="number">8</span>]]</span><br><span class="line"><span class="comment">#输入4维张量 得到8层结果 每一层都是3d图片</span></span><br><span class="line">activation_model = model.Model(inputs=model.<span class="built_in">input</span>,outputs=layer_outputs)</span><br><span class="line"></span><br><span class="line">activations = activation_model.predict(img_tensor)</span><br><span class="line"></span><br><span class="line">first_layer_activation = activations[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(first_layer_activation.shape)</span><br><span class="line"><span class="comment">#(1,148,148,32)</span></span><br><span class="line"><span class="comment">#第一层有32个滤镜 看看每个滤镜到底能看见什么</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.matshow(first_layer_activation[<span class="number">0</span>,:,:,<span class="number">3</span>],cmap=<span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021/07/08/%E6%9A%91%E5%81%87%E7%AC%AC%E4%BA%8C%E7%AF%87%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E6%97%A5%E5%BF%97/" rel="prev" title="暑假第二篇论文阅读日志">
                  <i class="fa fa-chevron-left"></i> 暑假第二篇论文阅读日志
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2021/07/25/21%E7%BA%A7%E7%A1%95%E5%A3%AB%E7%94%9F%E4%BA%A4%E6%B5%81%E4%BC%9A%E8%AE%B0%E5%BD%95/" rel="next" title="21级硕士生交流会记录">
                  21级硕士生交流会记录 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">kingFree</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  




  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
